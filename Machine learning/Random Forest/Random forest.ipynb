{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import precision_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import sem\n",
    "import joblib\n",
    "import hashlib\n",
    "import sqlite3\n",
    "from math import sin, cos, sqrt, atan2, radians, floor\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "\n",
    "# Methods\n",
    "def prepare_data(dataset, sample_frac=1):\n",
    "    df = dataset\n",
    "    temp = pd.DataFrame()\n",
    "#     temp[\"dest\"] = df['arrival_point']\n",
    "#     temp[\"dest_hash\"] = df['arrival_point'].apply(lambda x: my_hash(str(x)) if not None else None)\n",
    "    temp[\"dest_latitude\"] = df['arrival_point'].apply(lambda x: df_airport_data[\"latitude\"][x] if (x in df_airport_data.index) else None)\n",
    "    temp[\"dest_longitude\"] = df['arrival_point'].apply(lambda x: df_airport_data[\"longitude\"][x] if (x in df_airport_data.index) else None)\n",
    "#     temp[\"dest_square\"] = temp.apply(lambda x: get_grid_square(x[\"dest_latitude\"], x[\"dest_longitude\"]) if not None and not np.isnan(x[\"dest_latitude\"]) else None, axis=1)\n",
    "#     temp[\"dest_has_ils\"] = df['arrival_point'].apply(lambda x: \"ILS\" in df_airport_data[\"approaches\"][x] if (x in df_airport_data.index and isinstance(df_airport_data[\"approaches\"][x], str)) else False).astype(int)\n",
    "#     temp[\"dest_longest_runway\"] = df[\"arrival_point\"].apply(lambda x: df_airport_data[\"longest_runway\"][x] if (x in df_airport_data.index) else None)\n",
    "#     temp[\"dest_weather\"] = df[\"destination_airport_weather\"].map({'Flight category unknown': None, 'IFR': 0, 'low IFR': 1, 'Marginal VFR': 2, 'VFR': 3})\n",
    "#     temp[\"aircraft_type_icao\"] = df['aircraft_type_icao']\n",
    "#     temp[\"aircraft_type_icao_hash\"] = df['aircraft_type_icao'].apply(lambda x: my_hash(str(x)) if not None else None)\n",
    "#     temp[\"aircraft_max_landing_weight\"] = df['aircraft_type_icao'].apply(lambda x: df_aircraft_data[\"aircraft_max_landing_weight\"][x] if (x in df_aircraft_data.index) else None)\n",
    "#     temp[\"aircraft_weight_class\"] = temp['aircraft_max_landing_weight'].apply(lambda x: get_aircraft_weight_class(x))\n",
    "    temp[\"wake_turbulence\"] = df['wake_turbulence_category'].map({\"L\": 0, \"LIGHT\": 0, \"Light\": 0, \"M\": 1, \"MEDIUM\": 1, \"Medium\": 1, \"L/M\": 1, \"H\": 2, \"Heavy\": 2, \"J\": 3})\n",
    "#     temp[\"uses_ifr\"] = df[\"flight_rules\"].map({'IFR': 1, 'VFR': 0})\n",
    "#     temp[\"received_at_mm\"] = df[\"received_at\"].apply(lambda x: x[14:16]).astype(\"int16\")\n",
    "#     temp[\"received_at_HH\"] = df[\"received_at\"].apply(lambda x: x[11:13]).astype(\"int16\")\n",
    "#     temp[\"received_at_DD\"] = df[\"received_at\"].apply(lambda x: x[8:10]).astype(\"int16\")\n",
    "#     temp[\"received_at_MM\"] = df[\"received_at\"].apply(lambda x: x[5:7]).astype(\"int16\")\n",
    "#     temp[\"received_at_YY\"] = df[\"received_at\"].apply(lambda x: x[0:4]).astype(\"int16\")\n",
    "    temp[\"alternate_aerodrome\"] = df[\"alternate_aerodrome\"]\n",
    "#     temp[\"alternate_square\"] = temp.apply(lambda x: get_grid_square(df_airport_data[\"latitude\"][x[\"alternate_aerodrome\"]], df_airport_data[\"longitude\"][x[\"alternate_aerodrome\"]]) if (x[\"alternate_aerodrome\"] in df_airport_data.index) and not np.isnan(df_airport_data[\"latitude\"][x[\"alternate_aerodrome\"]]) else None, axis=1)\n",
    "    \n",
    "    temp = temp.dropna()\n",
    "    temp = temp.sample(frac=sample_frac, random_state=0)\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    df = temp\n",
    "    \n",
    "    X = df[[\n",
    "#              \"dest\",\n",
    "#              \"dest_hash\",\n",
    "             \"dest_latitude\",\n",
    "             \"dest_longitude\",\n",
    "#              \"dest_square\",\n",
    "#              \"dest_has_ils\",\n",
    "#              \"dest_longest_runway\",\n",
    "#              \"dest_weather\",\n",
    "#              \"aircraft_type_icao\",\n",
    "#              \"aircraft_type_icao_hash\",\n",
    "#              \"aircraft_max_landing_weight\",\n",
    "             \"wake_turbulence\",\n",
    "#              \"aircraft_weight_class\",\n",
    "#              \"uses_ifr\",\n",
    "#              \"received_at_mm\",\n",
    "#              \"received_at_HH\",\n",
    "#              \"received_at_DD\",\n",
    "#              \"received_at_MM\",\n",
    "#              \"received_at_YY\",\n",
    "           ]]\n",
    "    y = df[\"alternate_aerodrome\"]\n",
    "    \n",
    "    return df, X, y\n",
    "    \n",
    "\n",
    "def myround(x, base):\n",
    "    # Rounding to nearest integer n\n",
    "    return base * (x // base)\n",
    "\n",
    "def cyclic_encode(data, col, max_val):\n",
    "    # Encoding cyclic data (time and date) to make the model consider their cyclic nature.\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    del data[col]\n",
    "    return data\n",
    "\n",
    "def my_hash(string):\n",
    "    # Consistent hash method\n",
    "    return int(str(int(hashlib.sha256(string.encode('utf-8')).hexdigest(), base=16))[:10])\n",
    "\n",
    "def get_grid_square(lat, lon):\n",
    "    lat += 90\n",
    "    lon += 180\n",
    "    \n",
    "    lat_rounded = floor(lat)\n",
    "    lon_rounded = floor(lon)\n",
    "    \n",
    "#     square_id = 360 * lat_rounded + lon_rounded\n",
    "    square_id = 180 * lon_rounded + lat_rounded\n",
    "    return square_id\n",
    "\n",
    "def get_coords_from_square(square_id):\n",
    "#     lat_rounded = square_id // 360\n",
    "#     lon_rounded = square_id - 360 * lat_rounded\n",
    "    \n",
    "    lon_rounded = square_id // 180\n",
    "    lat_rounded = square_id - 180 * lon_rounded\n",
    "    \n",
    "    return [lat_rounded - 90, lon_rounded - 180]\n",
    "    \n",
    "\n",
    "def create_connection(db_file):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "def get_flight_plan_data(conn):\n",
    "    query = \"SELECT * FROM '1_mio_alternate_data' WHERE arrival_point LIKE 'K%' OR arrival_point LIKE 'E%' OR arrival_point LIKE 'L%' OR arrival_point LIKE 'C%'\"\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    \n",
    "    columns_names = list(map(lambda x: x[0], cur.description))\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    return rows, columns_names\n",
    "\n",
    "def get_airport_coords(conn):\n",
    "    query = \"SELECT ICAO, Latitude as latitude, Longitude AS longitude, LongestRunway AS longest_runway, HasILSApproach AS has_ils, HasRNAVApproach AS has_rnav, HasLocalizerApproach AS has_loc FROM (SELECT * FROM Airport INNER JOIN Point P on Airport.Point = P.Id) WHERE ICAO != ''\"\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    \n",
    "    columns_names = list(map(lambda x: x[0], cur.description))\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    return rows, columns_names\n",
    "\n",
    "def get_more_airport_data(conn):\n",
    "    query = \"SELECT alternates_airports_displayed_to_user as alternates, alternates_airport_is_towered_displayed_to_user AS has_tower, alternates_airport_approaches_displayed_to_user AS approaches FROM '1_mio_alternate_data'\"\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    \n",
    "    columns_names = list(map(lambda x: x[0], cur.description))\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    return rows, columns_names\n",
    "\n",
    "def get_aircraft_data(conn):\n",
    "    query = \"SELECT aircraft_type_icao, MAX(aircraft_max_landing_weight) AS aircraft_max_landing_weight, MIN(aircraft_min_runway_length) AS aircraft_min_runway_length FROM 'airplane_data (corrected with missing aircrafts) (from CSV)' GROUP BY (aircraft_type_icao)\"\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    \n",
    "    columns_names = list(map(lambda x: x[0], cur.description))\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    return rows, columns_names\n",
    "\n",
    "def get_aircraft_weight_class(weight):\n",
    "    if weight < 15500:\n",
    "        return 0\n",
    "    elif weight < 300000:\n",
    "        return 1\n",
    "    elif weight < 1234588:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def calc_coord_distance(lat1, lon1, lat2, lon2):\n",
    "    # Calculates distance between two points in km\n",
    "    \n",
    "    R = 6373.0    # Approximate radius of earth in km\n",
    "\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def airport_attractiveness_sort(dest, alternates):\n",
    "    sorted_alternates = []\n",
    "    for alternate_icao in alternates:\n",
    "        if alternate_icao == dest.icao:\n",
    "            continue\n",
    "        sorted_alternates.append(Alternate(alternate_icao, dest))\n",
    "    \n",
    "    sorted_alternates = sorted(sorted_alternates, key=lambda x: x.distance)\n",
    "    sorted_alternates = sorted(sorted_alternates, key=lambda x: x.has_tower, reverse=True)\n",
    "    \n",
    "    return sorted_alternates\n",
    "\n",
    "class Airport:\n",
    "    def __init__(self, icao):\n",
    "        self.icao = icao\n",
    "        self.lat = df_airport_data.loc[icao][\"latitude\"]\n",
    "        self.lon = df_airport_data.loc[icao][\"longitude\"]\n",
    "        self.has_tower = df_airport_data.loc[icao][\"has_tower\"]\n",
    "        self.approaches = df_airport_data.loc[icao][\"approaches\"]\n",
    "        self.has_ils = isinstance(self.approaches, str) and \"ILS\" in self.approaches\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"  - \" + str(self.icao) + \"{:10.3f}\".format(self.lat) + \"{:10.3f}\".format(self.lon) + \"\\tTower:\" + str(self.has_tower) + \"   Approaches:\" + str(self.approaches)\n",
    "\n",
    "class Alternate(Airport):\n",
    "    def __init__(self, icao, dest_airport):\n",
    "        super().__init__(icao)\n",
    "        self.distance = round(calc_coord_distance(dest_airport.lat, dest_airport.lon, self.lat, self.lon), 3)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"  - \" + str(self.icao) + \"{:10.3f}\".format(self.distance) + \"km\" + \"\\tTower:\" + str(self.has_tower) + \"   Approaches:\" + str(self.approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_in_top_ten(X_test, y_test, model, test_size):\n",
    "    # X_test and y_test need to be respectively a Pandas.DataFrame and a Pandas.Series\n",
    "    X_test_list = X_test.values.tolist()\n",
    "    y_test_list = y_test.tolist()\n",
    "    \n",
    "    n_correct = 0\n",
    "    for i in range(test_size):\n",
    "        if i % 200 == 0 and i != 0:\n",
    "            progress = round(i / test_size * 100, 2)\n",
    "            print(\"                                                                                    \", end=\"\\r\")\n",
    "            print(str(progress) + \"%    \", n_correct / i, end=\"\\r\")\n",
    "            \n",
    "        attributes = X_test_list[i]\n",
    "        predicted_alternates = model.classes_[model.predict_proba([attributes])[0].argsort()[-10:][::-1]]\n",
    "    \n",
    "        if (y_test_list[i] in predicted_alternates):\n",
    "            n_correct += 1\n",
    "    print(\"                                                                                    \", end=\"\\r\")\n",
    "    final_acc_top10 = n_correct / test_size\n",
    "    print(final_acc_top10)\n",
    "    return final_acc_top10\n",
    "\n",
    "def accuracy_score_own(X_test, y_test, model, test_size):\n",
    "    # X_test and y_test need to be respectively a Pandas.DataFrame and a Pandas.Series\n",
    "    X_test_list = X_test.values.tolist()\n",
    "    y_test_list = y_test.tolist()\n",
    "    \n",
    "    n_correct = 0\n",
    "    for i in range(test_size):\n",
    "        if i % 200 == 0 and i != 0:\n",
    "            progress = round(i / test_size * 100, 2)\n",
    "            print(\"                                                                                    \", end=\"\\r\")\n",
    "            print(str(progress) + \"%    \", n_correct / i, end=\"\\r\")\n",
    "            \n",
    "            \n",
    "        attributes = X_test_list[i]\n",
    "        predicted_alternates = model.classes_[model.predict_proba([attributes])[0].argsort()[-1:][::-1]]\n",
    "    \n",
    "        if (y_test_list[i] in predicted_alternates):\n",
    "            n_correct += 1\n",
    "    final_acc_own = n_correct / test_size\n",
    "    print(\"                                                                                    \", end=\"\\r\")\n",
    "    print(final_acc_own)\n",
    "    return final_acc_own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching airport coordinates\n",
    "conn = create_connection(\"data\\PE2014A\\PE2014A.sqlite\")\n",
    "rows, column_names = get_airport_coords(conn)\n",
    "df_airport_coords = pd.DataFrame(rows, columns=column_names)\n",
    "df_airport_coords = df_airport_coords.set_index(\"ICAO\")\n",
    "\n",
    "# Fethcing more airport features (tower, approaches) \n",
    "rows, column_names = get_more_airport_data(conn)\n",
    "df_airport_data = pd.DataFrame(rows, columns=column_names)\n",
    "for column in df_airport_data.columns:\n",
    "    df_airport_data[column] = df_airport_data[column].astype(str)\n",
    "\n",
    "airport_dict = {}\n",
    "\n",
    "for i, row in df_airport_data.iterrows():\n",
    "    if i % 10000 == 0:\n",
    "        progress = round(i / len(df_airport_data.index) * 100, 2)\n",
    "        print(str(progress) + \"%  \", end=\"\\r\")\n",
    "\n",
    "    alternates = row[\"alternates\"].split(\",\")\n",
    "    towers = row[\"has_tower\"].split(\",\")\n",
    "    approaches = row[\"approaches\"].replace(\", \", \";\").split(\",\")\n",
    "\n",
    "    for i in range(len(alternates)):\n",
    "        if alternates[i] not in airport_dict.keys():\n",
    "            value = []\n",
    "            value.append(1 if towers[i] == \"Towered\" else 0)\n",
    "            value.append(approaches[i])\n",
    "\n",
    "            airport_dict[alternates[i]] = value\n",
    "\n",
    "print(\"100%  \", end=\"\\r\")\n",
    "df_airport_data = pd.DataFrame.from_dict(airport_dict, orient='index', columns=[\"has_tower\", \"approaches\"])\n",
    "\n",
    "# Combining dataframes to make the one and only airport_data\n",
    "df_airport_data = pd.concat([df_airport_coords, df_airport_data], axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Aircraft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(\"data\\PE2014A\\PE2014A.sqlite\")\n",
    "\n",
    "rows, column_names = get_aircraft_data(conn)\n",
    "df_aircraft_data = pd.DataFrame(rows, columns=column_names)\n",
    "df_aircraft_data = df_aircraft_data.set_index(\"aircraft_type_icao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(\"data\\PE2014A\\PE2014A.sqlite\")\n",
    "rows, column_names = get_flight_plan_data(conn)\n",
    "dataset = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "dataframe, X, y = prepare_data(dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minMax = MinMaxScaler()\n",
    "# std_scaler = StandardScaler()\n",
    "\n",
    "# LabelEncoder\n",
    "if \"dest\" in X.columns:\n",
    "   X[\"dest\"] = LabelEncoder().fit_transform(X[\"dest\"]).tolist()\n",
    "if \"aircraft_type_icao\" in X.columns:\n",
    "   X[\"aircraft_type_icao\"] = LabelEncoder().fit_transform(X[\"aircraft_type_icao\"]).tolist()\n",
    "# if \"wake_turbulence\" in X.columns:\n",
    "#     X_waket = pd.DataFrame(X[\"wake_turbulence\"])\n",
    "# #     X_runw = pd.DataFrame(X[\"dest_longest_runway\"])\n",
    "#     X_wake = minMax.fit_transform(X_waket)\n",
    "# #     X_rnw = minMax.fit_transform(X_runw)\n",
    "#     del X[\"wake_turbulence\"]\n",
    "# #     del X[\"dest_longest_runway\"]\n",
    "\n",
    "#Normalize\n",
    "# X = pd.DataFrame(std_scaler.fit_transform(X), columns=X.columns)\n",
    "# joblib.dump(std_scaler, 'std_scaler.bin', compress=True)\n",
    "\n",
    "# X = pd.DataFrame(minMax.fit_transform(X), columns=X.columns)\n",
    "# joblib.dump(minMax, 'minMax.bin', compress=True)\n",
    "\n",
    "\n",
    "# X = pd.DataFrame(std_scaler.fit_transform(X), columns=X.columns)\n",
    "# # X[\"dest_longest_runway\"] = X_rnw\n",
    "# X[\"wake_turbulence\"] = X_wake\n",
    "# joblib.dump(minMax, 'minMax_lat_long_rnw_wake.bin', compress=True)\n",
    "# joblib.dump(std_scaler, 'stdScaler_lat_long_rnw_wake.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_data = []\n",
    "test_acc_std = None\n",
    "train_acc_std = None\n",
    "test_acc_top10 = None\n",
    "train_acc_top10 = None\n",
    "size = None\n",
    "\n",
    "testArray = [1]\n",
    "# testArray = [1]\n",
    "for k in testArray:\n",
    "    print(\"\\nStarting Random Forest with K value = : \", k)\n",
    "    model = RandomForestClassifier(criterion=\"entropy\", max_depth=13, n_estimators=40, max_features=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Starting test_acc_std\")\n",
    "    test_acc_std = accuracy_score_own(X_test, y_test, model, 30000)\n",
    "#     print(test_acc_std)\n",
    "    \n",
    "    print(\"Starting train_acc_std\")\n",
    "    train_acc_std = accuracy_score_own(X_train, y_train, model, 30000)\n",
    "#     print(train_acc_std)\n",
    "    \n",
    "    print(\"Starting test_acc_top10\")\n",
    "    test_acc_top10 = accuracy_score_in_top_ten(X_test, y_test, model, 30000)\n",
    "#     print(test_acc_top10)\n",
    "    \n",
    "    print(\"Starting train_acc_top10\")\n",
    "    train_acc_top10 = accuracy_score_in_top_ten(X_train, y_train, model, 30000)\n",
    "#     print(train_acc_top10)\n",
    "\n",
    "    \n",
    "#     # Calculating size\n",
    "#     file_name =  \"./random_forest_nestimators_\" + str(k) + \".joblib\"\n",
    "#     joblib.dump(model, file_name)\n",
    "#     size = os.path.getsize(file_name) / (1024 ** 2)  # Converting to MB\n",
    "#     os.remove(file_name)\n",
    "#     print(size)\n",
    "    \n",
    "    k_data.append({\"k\": k,\n",
    "                  \"test_acc_std\": test_acc_std,\n",
    "                  \"train_acc_std\": train_acc_std,\n",
    "                  \"test_acc_top10\": test_acc_top10,\n",
    "                  \"train_acc_top10\": train_acc_top10,\n",
    "                  \"size\": size})\n",
    "\n",
    "print(k_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "12b401dac0c62dd3eca890af5ba2eda3fd6dec6671583bfba6062cd67ae30c87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
